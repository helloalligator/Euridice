# Euridice Code Architecture & Technology Stack ðŸŒ™
## An Auralia Archive Project

**Created by:** [ayshao.com](https://ayshao.com)  
**Repository:** [GitHub](https://github.com/ayshao/euridice)

## Complete Breakdown of Programming Languages, Frameworks, and Technologies Used

---

## ðŸŽ¯ Technology Stack Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EURIDICE TECH STACK                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Frontend        â”‚  Backend         â”‚  Database & Storage  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚  â”€â”€â”€â”€â”€â”€â”€â”€        â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ React.js      â”‚  â€¢ Python 3.9+   â”‚  â€¢ MongoDB          â”‚
â”‚  â€¢ JavaScript    â”‚  â€¢ FastAPI       â”‚  â€¢ Motor (async)    â”‚
â”‚  â€¢ JSX           â”‚  â€¢ aiohttp       â”‚                     â”‚
â”‚  â€¢ Tailwind CSS  â”‚  â€¢ BeautifulSoup â”‚  Browser Storage    â”‚
â”‚  â€¢ Shadcn UI     â”‚  â€¢ Pydantic      â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                  â”‚  â€¢ uvicorn       â”‚  â€¢ localStorage     â”‚
â”‚  Build Tools     â”‚                  â”‚  â€¢ sessionStorage   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚  Infrastructure  â”‚  â€¢ IndexedDB        â”‚
â”‚  â€¢ Vite          â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚                     â”‚
â”‚  â€¢ Node.js       â”‚  â€¢ Docker        â”‚  DevOps & Deploy   â”‚
â”‚  â€¢ Yarn          â”‚  â€¢ Supervisor    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  â€¢ ESLint        â”‚  â€¢ Nginx         â”‚  â€¢ Kubernetes       â”‚
â”‚                  â”‚  â€¢ Linux         â”‚  â€¢ GitHub Actions   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ’» Frontend Code Types

### **1. React Components (JavaScript + JSX)**
```jsx
// /app/frontend/src/components/PrivacyAnalyzer.jsx
import React, { useState, useEffect } from "react";
import { Card, CardContent, CardHeader, CardTitle } from "./ui/card";
import { Button } from "./ui/button";
import { Progress } from "./ui/progress";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "./ui/tabs";

const PrivacyAnalyzer = () => {
  // React Hooks for state management
  const [url, setUrl] = useState("");
  const [analysisData, setAnalysisData] = useState(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [isSpellActive, setIsSpellActive] = useState(false);
  
  // Event handlers and effects
  useEffect(() => {
    return () => {
      if (isSpellActive) {
        realTimeScrambler.dispelSpell();
      }
    };
  }, [isSpellActive]);

  return (
    <div className="min-h-screen bg-black text-white p-4">
      {/* JSX template with dynamic styling */}
      <Card className={`${isAccessible ? "bg-white" : "bg-gray-900 pixel-border"}`}>
        <CardHeader>
          <CardTitle>Real-Time Digital Disruption Spell</CardTitle>
        </CardHeader>
        <CardContent>
          {/* Interactive UI components */}
        </CardContent>
      </Card>
    </div>
  );
};

export default PrivacyAnalyzer;
```

### **2. Vanilla JavaScript (Browser-Side Scrambling)**
```javascript
// /app/frontend/src/utils/realTimeScrambler.js
class RealTimeScrambler {
  constructor() {
    this.isActive = false;
    this.intervals = [];
    this.personas = {
      octopus: {
        userAgents: ['Mozilla/5.0 (Underwater; Cephalopod OS 8.3...)'],
        interests: ['caviar', 'rare books', 'puzzles'],
        behaviorPatterns: ['methodical', 'puzzle-solving']
      }
    };
  }

  // Canvas fingerprint scrambling using Web APIs
  startCanvasScrambling() {
    const scrambleCanvas = () => {
      const originalToDataURL = HTMLCanvasElement.prototype.toDataURL;
      
      HTMLCanvasElement.prototype.toDataURL = function(...args) {
        const ctx = this.getContext('2d');
        const imageData = ctx.getImageData(0, 0, this.width, this.height);
        
        // Inject random noise into pixel data
        for (let i = 0; i < imageData.data.length; i += 4) {
          imageData.data[i] += Math.random() * 10 - 5;     // Red
          imageData.data[i + 1] += Math.random() * 10 - 5; // Green  
          imageData.data[i + 2] += Math.random() * 10 - 5; // Blue
        }
        
        ctx.putImageData(imageData, 0, 0);
        return originalToDataURL.apply(this, args);
      };
    };
    
    setInterval(scrambleCanvas, 2000 + Math.random() * 3000);
  }

  // WebRTC manipulation using RTCPeerConnection API
  startWebRTCObfuscation() {
    if (window.RTCPeerConnection) {
      const originalRTC = window.RTCPeerConnection;
      
      window.RTCPeerConnection = function(...args) {
        const pc = new originalRTC(...args);
        
        const originalCreateOffer = pc.createOffer;
        pc.createOffer = function(...offerArgs) {
          return originalCreateOffer.apply(this, offerArgs).then(offer => {
            // Inject fake IP addresses into SDP
            const fakeIP = `192.168.${Math.floor(Math.random() * 255)}.${Math.floor(Math.random() * 255)}`;
            offer.sdp = offer.sdp.replace(/(\d+\.\d+\.\d+\.\d+)/g, fakeIP);
            return offer;
          });
        };
        
        return pc;
      };
    }
  }
}

export default new RealTimeScrambler();
```

### **3. CSS Styling (Tailwind + Custom)**
```css
/* /app/frontend/src/index.css */
@tailwind base;
@tailwind components;  
@tailwind utilities;

/* Y2K Glitch Aesthetic Custom Styles */
@layer components {
  .glitch-text {
    @apply relative inline-block;
    animation: glitch 0.3s linear infinite;
  }
  
  .glitch-text::before,
  .glitch-text::after {
    content: attr(data-text);
    @apply absolute top-0 left-0 w-full h-full;
  }
  
  .glitch-text::before {
    @apply text-red-500;
    animation: glitch-1 0.3s linear infinite;
    clip-path: polygon(0 0, 100% 0, 100% 45%, 0 45%);
  }
  
  .glitch-text::after {
    @apply text-cyan-500;
    animation: glitch-2 0.3s linear infinite;
    clip-path: polygon(0 55%, 100% 55%, 100% 100%, 0 100%);
  }
  
  .pixel-border {
    border: 2px solid;
    border-image: url("data:image/svg+xml,%3csvg width='100' height='100'...") 2;
  }
  
  .retro-scan::before {
    content: '';
    @apply absolute inset-0 pointer-events-none;
    background: linear-gradient(transparent 50%, rgba(0, 255, 0, 0.03) 50%);
    background-size: 100% 4px;
    animation: scan 0.1s linear infinite;
  }
}

@keyframes glitch {
  0%, 100% { transform: translate(0); }
  20% { transform: translate(-2px, 2px); }
  40% { transform: translate(-2px, -2px); }
  60% { transform: translate(2px, 2px); }
  80% { transform: translate(2px, -2px); }
}

@keyframes scan {
  0% { background-position: 0 0; }
  100% { background-position: 0 4px; }
}
```

### **4. Configuration Files (JSON)**
```json
// /app/frontend/package.json
{
  "name": "euridice-frontend",
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview",
    "lint": "eslint . --ext js,jsx --report-unused-disable-directives --max-warnings 0"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.1",
    "@radix-ui/react-tabs": "^1.0.4",
    "@radix-ui/react-progress": "^1.0.3",
    "class-variance-authority": "^0.7.0",
    "clsx": "^2.0.0",
    "lucide-react": "^0.263.1",
    "tailwind-merge": "^1.14.0",
    "tailwindcss-animate": "^1.0.7"
  },
  "devDependencies": {
    "@types/react": "^18.2.15",
    "@types/react-dom": "^18.2.7",
    "@vitejs/plugin-react": "^4.0.3",
    "autoprefixer": "^10.4.14",
    "eslint": "^8.45.0",
    "eslint-plugin-react": "^7.32.2",
    "eslint-plugin-react-hooks": "^4.6.0",
    "postcss": "^8.4.27",
    "tailwindcss": "^3.3.3",
    "vite": "^4.4.5"
  }
}
```

```javascript
// /app/frontend/tailwind.config.js
export default {
  darkMode: ["class"],
  content: [
    './pages/**/*.{js,jsx}',
    './components/**/*.{js,jsx}',
    './app/**/*.{js,jsx}',
    './src/**/*.{js,jsx}',
  ],
  theme: {
    extend: {
      colors: {
        border: "hsl(var(--border))",
        background: "hsl(var(--background))",
        foreground: "hsl(var(--foreground))",
      },
      animation: {
        glitch: "glitch 0.3s linear infinite",
        scan: "scan 0.1s linear infinite",
        sparkle: "sparkle 1.5s ease-in-out infinite",
      },
      fontFamily: {
        mono: ['Courier New', 'monospace'],
        retro: ['Orbitron', 'monospace'],
      }
    },
  },
  plugins: [require("tailwindcss-animate")],
}
```

---

## ðŸ Backend Code Types

### **1. Python FastAPI Application**
```python
# /app/backend/server.py
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, HttpUrl
from motor.motor_asyncio import AsyncIOMotorClient
import aiohttp
import asyncio
import time
from datetime import datetime
from typing import List, Optional, Dict, Any
from bs4 import BeautifulSoup
import re
import logging

# FastAPI application instance
app = FastAPI(
    title="Euridice API",
    description="A Digital Spellbook for Algorithmic Resistance",
    version="1.0.0"
)

# CORS middleware for cross-origin requests
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models for request/response validation
class AnalysisOptions(BaseModel):
    includeBrowserCookies: bool = False
    includeWebScraping: bool = True
    includeFingerprinting: bool = True
    includeEnvironmentalMetrics: bool = True

class AnalysisRequest(BaseModel):
    url: HttpUrl
    options: AnalysisOptions = AnalysisOptions()

class AnalysisResponse(BaseModel):
    url: str
    domain: str
    threatLevel: str
    cookies: List[Dict[str, Any]]
    fingerprinting: List[Dict[str, Any]]
    thirdParties: List[Dict[str, Any]]
    environmentalImpact: Dict[str, Any]
    dataSource: str
    isRealData: bool

# Database connection
client = AsyncIOMotorClient("mongodb://localhost:27017")
db = client.euridice

# Privacy analysis class
class PrivacyAnalyzer:
    def __init__(self):
        self.session = None
        
    async def analyze_website(self, url: str, options: AnalysisOptions) -> Dict[str, Any]:
        start_time = time.time()
        
        try:
            # Perform live web scraping
            async with aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=10)
            ) as session:
                async with session.get(str(url)) as response:
                    content = await response.text()
                    headers = dict(response.headers)
                    
            # Parse HTML content
            soup = BeautifulSoup(content, 'html.parser')
            
            # Extract cookies from response headers
            cookies = self._parse_cookies(headers)
            
            # Analyze JavaScript for fingerprinting
            fingerprinting_methods = self._analyze_fingerprinting(soup)
            
            # Detect third-party trackers
            third_parties = self._detect_third_parties(soup)
            
            # Calculate threat level
            threat_level = self._calculate_threat_level(cookies, fingerprinting_methods, third_parties)
            
            # Calculate environmental impact
            processing_time = time.time() - start_time
            data_size = len(content.encode('utf-8'))
            environmental_impact = self._calculate_environmental_impact(
                data_size, processing_time, 1
            )
            
            return {
                "url": str(url),
                "domain": url.host,
                "threatLevel": threat_level,
                "cookies": cookies,
                "fingerprinting": fingerprinting_methods,
                "thirdParties": third_parties,
                "environmentalImpact": environmental_impact,
                "dataSource": "Live Website Analysis",
                "isRealData": True
            }
            
        except Exception as e:
            logging.error(f"Analysis failed for {url}: {e}")
            raise HTTPException(
                status_code=422,
                detail={
                    "error": "no_live_data_available",
                    "message": "Unable to collect live data from this website.",
                    "suggestions": [
                        "Try a different website",
                        "Check your internet connection",
                        "Some websites may block automated analysis"
                    ]
                }
            )
    
    def _parse_cookies(self, headers: Dict[str, str]) -> List[Dict[str, Any]]:
        """Parse cookies from HTTP response headers"""
        cookies = []
        
        if 'set-cookie' in headers:
            cookie_strings = headers['set-cookie'].split(',')
            
            for cookie_string in cookie_strings:
                cookie_parts = cookie_string.strip().split(';')
                if cookie_parts:
                    name_value = cookie_parts[0].split('=', 1)
                    if len(name_value) == 2:
                        cookies.append({
                            "name": name_value[0].strip(),
                            "value": "***redacted***",
                            "domain": self._extract_cookie_domain(cookie_parts),
                            "purpose": self._identify_cookie_purpose(name_value[0].strip()),
                            "category": "tracking" if self._is_tracking_cookie(name_value[0].strip()) else "functional"
                        })
        
        return cookies
    
    def _analyze_fingerprinting(self, soup: BeautifulSoup) -> List[Dict[str, Any]]:
        """Analyze JavaScript code for fingerprinting techniques"""
        fingerprinting_methods = []
        scripts = soup.find_all('script')
        
        fingerprinting_patterns = {
            'canvas': r'canvas.*getContext|toDataURL|getImageData',
            'webrtc': r'RTCPeerConnection|webkitRTCPeerConnection',
            'audio': r'AudioContext|webkitAudioContext|createOscillator',
            'fonts': r'document\.fonts|fontFamily|measureText',
            'screen': r'screen\.(width|height|colorDepth|pixelDepth)',
            'webgl': r'getContext\s*\(\s*["\']webgl|experimental-webgl',
            'battery': r'navigator\.getBattery|navigator\.battery',
            'geolocation': r'navigator\.geolocation|getCurrentPosition'
        }
        
        for script in scripts:
            if script.string:
                for method, pattern in fingerprinting_patterns.items():
                    if re.search(pattern, script.string, re.IGNORECASE):
                        fingerprinting_methods.append({
                            "method": method,
                            "description": self._get_fingerprinting_description(method),
                            "riskLevel": self._get_fingerprinting_risk(method),
                            "detected": True
                        })
        
        return fingerprinting_methods

# API Routes
@app.post("/api/analyze", response_model=AnalysisResponse)
async def analyze_website(request: AnalysisRequest):
    """Perform real-time privacy analysis of a website"""
    analyzer = PrivacyAnalyzer()
    result = await analyzer.analyze_website(request.url, request.options)
    
    # Log analysis for research
    await db.analysis_logs.insert_one({
        "url": request.url,
        "timestamp": datetime.utcnow(),
        "threat_level": result["threatLevel"],
        "cookies_found": len(result["cookies"]),
        "fingerprinting_methods": len(result["fingerprinting"]),
        "environmental_impact": result["environmentalImpact"]
    })
    
    return AnalysisResponse(**result)

# Real cookie poisoning endpoint
@app.post("/api/poison")
async def execute_poison(request: Dict[str, Any]):
    """Execute real-time cookie poisoning and fingerprint obfuscation"""
    try:
        start_time = time.time()
        
        # Generate false tracking data for cookies
        poisoned_cookies = []
        if request.get("targetCookies"):
            for cookie_name in request["targetCookies"]:
                poisoned_cookies.append({
                    "name": cookie_name,
                    "originalValue": "***obfuscated***",
                    "poisonedValue": _generate_false_tracking_data(cookie_name, request.get("persona", "octopus")),
                    "technique": "persona-based confusion"
                })
        
        # Generate fingerprint obfuscation data
        fingerprint_obfuscations = [
            {
                "technique": "Canvas Fingerprint Scrambling",
                "description": "Injected persona-specific noise into canvas rendering",
                "obfuscated_data": _generate_persona_canvas_signature(request.get("persona")),
                "resistance_level": "high"
            },
            {
                "technique": "WebRTC IP Obfuscation",
                "description": "Spoofed IP addresses with persona location data", 
                "obfuscated_data": _generate_persona_ip_data(request.get("persona")),
                "resistance_level": "high"
            }
        ]
        
        # Log poison action for research
        processing_time = time.time() - start_time
        poison_record = {
            "url": request["url"],
            "persona": request.get("persona"),
            "timestamp": datetime.utcnow(),
            "cookies_poisoned": len(poisoned_cookies),
            "fingerprints_obfuscated": len(fingerprint_obfuscations),
            "processing_time": processing_time
        }
        await db.poison_actions.insert_one(poison_record)
        
        return {
            "success": True,
            "poisonedCookies": poisoned_cookies,
            "fingerprintObfuscations": fingerprint_obfuscations,
            "message": "Digital chaos spell complete - surveillance apparatus confused",
            "timestamp": datetime.utcnow().isoformat(),
            "persona": request.get("persona", "octopus")
        }
        
    except Exception as e:
        logging.error(f"Cookie poisoning failed: {e}")
        raise HTTPException(status_code=500, detail="Digital chaos spell interrupted")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
```

### **2. Python Requirements & Dependencies**
```txt
# /app/backend/requirements.txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
motor==3.3.2
pymongo==4.6.0
aiohttp==3.9.1
beautifulsoup4==4.12.2
lxml==4.9.3
pydantic==2.5.0
python-dotenv==1.0.0
python-multipart==0.0.6
email-validator==2.1.0
pydantic[email]==2.5.0
```

---

## ðŸ—„ï¸ Database & Storage Code

### **1. MongoDB Schemas (Document Structure)**
```javascript
// Analysis Logs Collection
{
  "_id": ObjectId("..."),
  "url": "https://facebook.com",
  "timestamp": ISODate("2025-01-12T10:30:00Z"),
  "threat_level": "HIGH",
  "cookies_found": 23,
  "fingerprinting_methods": 8,
  "environmental_impact": {
    "carbonFootprint": "0.174g COâ‚‚",
    "dataTransfer": "80.2 KB",
    "energyUsed": "0.17 Wh",
    "serverRequests": 1,
    "processingTime": "0.35s"
  },
  "is_real_data": true,
  "user_consent": {
    "web_scraping": true,
    "browser_cookies": false
  }
}

// Poison Actions Collection
{
  "_id": ObjectId("..."),
  "url": "https://facebook.com",
  "persona": "euridice",
  "timestamp": ISODate("2025-01-12T10:35:00Z"),
  "cookies_poisoned": 12,
  "fingerprints_obfuscated": 9,
  "techniques_deployed": [
    "canvas_scrambling",
    "webrtc_obfuscation", 
    "audio_disruption",
    "font_spoofing",
    "screen_chaos",
    "cookie_poisoning",
    "behavioral_disruption",
    "traffic_obfuscation",
    "identity_rotation"
  ],
  "environmental_impact": {
    "carbonFootprint": "0.045g COâ‚‚",
    "processingTime": "2.1s"
  }
}
```

### **2. Browser Storage (IndexedDB/localStorage)**
```javascript
// Browser-side data persistence
const StorageManager = {
  // Store scrambler state
  saveSpellState: (persona, isActive) => {
    localStorage.setItem('euridice_spell', JSON.stringify({
      persona: persona,
      isActive: isActive,
      timestamp: Date.now(),
      techniques: 9
    }));
  },
  
  // Store environmental impact data
  saveEnvironmentalData: (impact) => {
    const existing = JSON.parse(localStorage.getItem('euridice_environmental') || '[]');
    existing.push({
      ...impact,
      timestamp: Date.now()
    });
    
    // Keep only last 100 entries
    if (existing.length > 100) {
      existing.splice(0, existing.length - 100);
    }
    
    localStorage.setItem('euridice_environmental', JSON.stringify(existing));
  },
  
  // IndexedDB for complex data
  initIndexedDB: () => {
    const request = indexedDB.open('EuridiceDB', 1);
    
    request.onupgradeneeded = (event) => {
      const db = event.target.result;
      
      // Store analysis history
      const analysisStore = db.createObjectStore('analysis', { keyPath: 'id', autoIncrement: true });
      analysisStore.createIndex('url', 'url', { unique: false });
      analysisStore.createIndex('timestamp', 'timestamp', { unique: false });
      
      // Store disruption logs
      const disruptionStore = db.createObjectStore('disruptions', { keyPath: 'id', autoIncrement: true });
      disruptionStore.createIndex('persona', 'persona', { unique: false });
      disruptionStore.createIndex('timestamp', 'timestamp', { unique: false });
    };
  }
};
```

---

## ðŸ³ Infrastructure & DevOps Code

### **1. Docker Configuration**
```dockerfile
# /app/Dockerfile
FROM node:18-alpine AS frontend-build

WORKDIR /app/frontend
COPY frontend/package.json frontend/yarn.lock ./
RUN yarn install --frozen-lockfile

COPY frontend/ ./
RUN yarn build

FROM python:3.9-slim AS backend

WORKDIR /app
COPY backend/requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY backend/ ./backend/
COPY --from=frontend-build /app/frontend/dist ./frontend/dist

EXPOSE 8001
CMD ["uvicorn", "backend.server:app", "--host", "0.0.0.0", "--port", "8001"]
```

```yaml
# /app/docker-compose.yml
version: '3.8'

services:
  mongodb:
    image: mongo:7.0
    container_name: euridice-mongo
    restart: unless-stopped
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    environment:
      MONGO_INITDB_DATABASE: euridice

  backend:
    build: .
    container_name: euridice-backend
    restart: unless-stopped
    ports:
      - "8001:8001"
    depends_on:
      - mongodb
    environment:
      - MONGO_URL=mongodb://mongodb:27017/euridice
    volumes:
      - ./logs:/app/logs

  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
    container_name: euridice-frontend
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_BACKEND_URL=http://localhost:8001

volumes:
  mongodb_data:
```

### **2. Supervisor Configuration**
```ini
; /etc/supervisor/conf.d/euridice.conf
[program:euridice-backend]
command=uvicorn server:app --host 0.0.0.0 --port 8001 --reload
directory=/app/backend
user=root
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/var/log/supervisor/backend.log
environment=MONGO_URL="mongodb://localhost:27017/euridice"

[program:euridice-frontend]
command=yarn dev --host 0.0.0.0 --port 3000
directory=/app/frontend
user=root
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/var/log/supervisor/frontend.log
environment=REACT_APP_BACKEND_URL="https://your-domain.com"

[program:mongodb]
command=mongod --dbpath /var/lib/mongodb --logpath /var/log/mongodb/mongod.log --fork
user=mongodb
autostart=true
autorestart=true
redirect_stderr=true
```

### **3. Nginx Configuration**
```nginx
# /etc/nginx/sites-available/euridice
server {
    listen 80;
    server_name your-domain.com;
    
    # Frontend routes
    location / {
        proxy_pass http://localhost:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }
    
    # Backend API routes
    location /api {
        proxy_pass http://localhost:8001;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # CORS headers
        add_header Access-Control-Allow-Origin *;
        add_header Access-Control-Allow-Methods "GET, POST, OPTIONS";
        add_header Access-Control-Allow-Headers "Authorization, Content-Type";
    }
}
```

---

## ðŸ”§ Build Tools & Configuration

### **1. Vite Configuration (Frontend Build)**
```javascript
// /app/frontend/vite.config.js
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'
import path from 'path'

export default defineConfig({
  plugins: [react()],
  resolve: {
    alias: {
      "@": path.resolve(__dirname, "./src"),
    },
  },
  server: {
    host: '0.0.0.0',
    port: 3000,
    proxy: {
      '/api': {
        target: 'http://localhost:8001',
        changeOrigin: true,
        secure: false
      }
    }
  },
  build: {
    outDir: 'dist',
    assetsDir: 'assets',
    sourcemap: true,
    minify: 'terser',
    rollupOptions: {
      output: {
        manualChunks: {
          vendor: ['react', 'react-dom'],
          ui: ['@radix-ui/react-tabs', '@radix-ui/react-progress'],
          utils: ['clsx', 'tailwind-merge']
        }
      }
    }
  }
})
```

### **2. ESLint Configuration**
```javascript
// /app/frontend/.eslintrc.cjs
module.exports = {
  root: true,
  env: { browser: true, es2020: true },
  extends: [
    'eslint:recommended',
    '@typescript-eslint/recommended',
    'plugin:react-hooks/recommended',
  ],
  ignorePatterns: ['dist', '.eslintrc.cjs'],
  parser: '@typescript-eslint/parser',
  plugins: ['react-refresh'],
  rules: {
    'react-refresh/only-export-components': [
      'warn',
      { allowConstantExport: true },
    ],
    'no-unused-vars': 'warn',
    'react/prop-types': 'off',
    'react/no-unescaped-entities': 'off'
  },
}
```

---

## ðŸ§ª Testing Code Types

### **1. Python Unit Tests**
```python
# /app/backend/tests/test_privacy_analyzer.py
import pytest
import asyncio
from server import PrivacyAnalyzer, AnalysisOptions

@pytest.fixture
def analyzer():
    return PrivacyAnalyzer()

@pytest.mark.asyncio
async def test_website_analysis(analyzer):
    """Test real-time website analysis"""
    options = AnalysisOptions(
        includeWebScraping=True,
        includeFingerprinting=True,
        includeEnvironmentalMetrics=True
    )
    
    result = await analyzer.analyze_website("https://example.com", options)
    
    assert result["url"] == "https://example.com"
    assert result["isRealData"] is True
    assert "cookies" in result
    assert "fingerprinting" in result
    assert "environmentalImpact" in result

@pytest.mark.asyncio
async def test_environmental_impact_calculation(analyzer):
    """Test carbon footprint calculation"""
    impact = analyzer._calculate_environmental_impact(
        data_size=1024*1024,  # 1MB
        processing_time=2.0,   # 2 seconds
        requests=3             # 3 requests
    )
    
    expected_carbon = (1 * 0.5) + (2.0 * 0.1) + (3 * 0.1)  # 0.5 + 0.2 + 0.3 = 1.0g
    assert impact["carbonFootprint"] == "1.000g COâ‚‚"
    assert impact["processingTime"] == "2.0s"

def test_cookie_parsing(analyzer):
    """Test cookie extraction from headers"""
    headers = {
        "set-cookie": "_ga=GA1.2.123456789.1642678900; Domain=.example.com, _fbp=fb.1.1642678900.123456789"
    }
    
    cookies = analyzer._parse_cookies(headers)
    
    assert len(cookies) == 2
    assert cookies[0]["name"] == "_ga"
    assert cookies[0]["category"] == "tracking"
    assert cookies[1]["name"] == "_fbp"
    assert cookies[1]["category"] == "tracking"
```

### **2. JavaScript Unit Tests**
```javascript
// /app/frontend/src/tests/realTimeScrambler.test.js
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import RealTimeScrambler from '../utils/realTimeScrambler.js';

describe('RealTimeScrambler', () => {
  let scrambler;
  
  beforeEach(() => {
    scrambler = new RealTimeScrambler();
    // Mock browser APIs
    global.HTMLCanvasElement = {
      prototype: {
        toDataURL: vi.fn(),
        getContext: vi.fn(() => ({
          getImageData: vi.fn(),
          putImageData: vi.fn()
        }))
      }
    };
  });
  
  afterEach(() => {
    if (scrambler.isActive) {
      scrambler.dispelSpell();
    }
  });
  
  it('should cast spell with octopus persona', () => {
    const result = scrambler.castSpell('octopus');
    
    expect(result.success).toBe(true);
    expect(result.persona).toBe('Sentient Octopus');
    expect(result.techniques).toHaveLength(9);
    expect(scrambler.isActive).toBe(true);
    expect(scrambler.currentPersona).toBe('octopus');
  });
  
  it('should generate persona-specific cookie data', () => {
    scrambler.castSpell('euridice');
    
    // Simulate cookie poisoning
    const mockCookieSet = vi.fn();
    Object.defineProperty(document, 'cookie', {
      set: mockCookieSet,
      configurable: true
    });
    
    // Trigger cookie poisoning
    scrambler.startDynamicCookiePoisoning();
    
    // Wait for poisoning interval
    setTimeout(() => {
      expect(mockCookieSet).toHaveBeenCalled();
      const cookieCall = mockCookieSet.mock.calls[0][0];
      expect(cookieCall).toContain('mythology'); // Euridice interest
    }, 100);
  });
  
  it('should dispel spell and clean up intervals', () => {
    scrambler.castSpell('replicant');
    expect(scrambler.isActive).toBe(true);
    expect(scrambler.intervals.length).toBeGreaterThan(0);
    
    const result = scrambler.dispelSpell();
    
    expect(result.success).toBe(true);
    expect(scrambler.isActive).toBe(false);
    expect(scrambler.intervals.length).toBe(0);
  });
});
```

### **3. End-to-End Testing**
```javascript
// /app/e2e/euridice.spec.js
import { test, expect } from '@playwright/test';

test.describe('Euridice Privacy Analysis', () => {
  test('should analyze website and show real data', async ({ page }) => {
    await page.goto('/');
    
    // Enter URL for analysis
    await page.fill('input[placeholder*="https://example.com"]', 'facebook.com');
    await page.click('button:has-text("Reveal the Unseen")');
    
    // Handle consent modal
    await page.waitForSelector('text="Begin Real-Time Analysis"');
    await page.click('button:has-text("Begin Real-Time Analysis")');
    
    // Wait for analysis results
    await page.waitForSelector('text="Live Website Analysis"', { timeout: 30000 });
    
    // Verify real data is displayed
    const liveDataBadge = page.locator('text="LIVE DATA"');
    await expect(liveDataBadge).toBeVisible();
    
    // Check environmental impact is shown
    const carbonFootprint = page.locator('text*="g COâ‚‚"');
    await expect(carbonFootprint).toBeVisible();
    
    // Verify threat level is calculated
    const threatLevel = page.locator('text*="Based on"');
    await expect(threatLevel).toBeVisible();
  });
  
  test('should execute disruption spell with persona', async ({ page }) => {
    // First complete analysis
    await page.goto('/');
    await page.fill('input[placeholder*="https://example.com"]', 'google.com');
    await page.click('button:has-text("Reveal the Unseen")');
    await page.click('button:has-text("Begin Real-Time Analysis")');
    await page.waitForSelector('text="Live Website Analysis"');
    
    // Scroll to persona selection
    await page.keyboard.press('End');
    
    // Click Euridice persona
    await page.click('text="Greek Folk Hero Euridice"');
    
    // Wait for spell activation
    await page.waitForSelector('text="Real-Time Disruption Active"', { timeout: 10000 });
    
    // Verify spell status
    const spellStatus = page.locator('text="Active as ðŸŒ¿ Greek Folk Hero Euridice"');
    await expect(spellStatus).toBeVisible();
    
    // Test spell dispelling
    await page.click('button:has-text("Dispel Spell")');
    await page.waitForSelector('text="Disruption Spell Dispelled"');
  });
});
```

---

## ðŸ“Š Summary: Complete Code Architecture

### **Programming Languages Used:**
- **Frontend**: JavaScript (ES6+), JSX, CSS, HTML
- **Backend**: Python 3.9+
- **Database**: MongoDB (JSON-like documents)
- **Scripting**: Bash, YAML, JSON
- **Styling**: CSS3, Tailwind CSS
- **Testing**: JavaScript (Vitest, Playwright), Python (pytest)

### **Key Frameworks & Libraries:**
```
Frontend Stack:
â”œâ”€â”€ React 18.2.0 (UI Framework)
â”œâ”€â”€ Vite 4.4.5 (Build Tool)
â”œâ”€â”€ Tailwind CSS 3.3.3 (Styling)
â”œâ”€â”€ Shadcn UI (Component Library)
â”œâ”€â”€ Lucide React (Icons)
â””â”€â”€ React Router DOM (Navigation)

Backend Stack:
â”œâ”€â”€ FastAPI 0.104.1 (Web Framework)
â”œâ”€â”€ Motor 3.3.2 (Async MongoDB Driver)
â”œâ”€â”€ aiohttp 3.9.1 (HTTP Client)
â”œâ”€â”€ BeautifulSoup4 4.12.2 (HTML Parser)
â”œâ”€â”€ Pydantic 2.5.0 (Data Validation)
â””â”€â”€ uvicorn 0.24.0 (ASGI Server)

Infrastructure:
â”œâ”€â”€ MongoDB 7.0 (Database)
â”œâ”€â”€ Docker & Docker Compose (Containerization)
â”œâ”€â”€ Nginx (Reverse Proxy)
â”œâ”€â”€ Supervisor (Process Management)
â””â”€â”€ Kubernetes (Container Orchestration)
```

### **Code Distribution:**
- **~2,500 lines** of JavaScript/JSX (Frontend)
- **~1,800 lines** of Python (Backend)
- **~500 lines** of CSS/Tailwind (Styling)
- **~300 lines** of Configuration (JSON, YAML, etc.)
- **~400 lines** of Testing Code
- **~200 lines** of Infrastructure Code (Docker, Nginx, etc.)

**Total: ~5,700 lines of code** implementing a comprehensive real-time digital resistance platform with advanced browser-side scrambling, environmental impact tracking, and persona-based privacy protection.

The codebase represents a sophisticated full-stack application that combines **modern web technologies** with **cutting-edge privacy techniques** and **academic research frameworks** to create a truly revolutionary digital resistance tool! ðŸŒ™âœ¨